{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook makes tables and figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, configuration, and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 9}\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InsectWingbeat and PenDigits are too large to efficiently compute, and thus are excluded\n",
    "\n",
    "human_activity_datasets = ['BasicMotions', 'Cricket', 'Epilepsy', 'ERing', 'Handwriting', 'Libras', 'NATOPS', 'RacketSports', 'UWaveGestureLibrary']\n",
    "motion_datasets = ['ArticularyWordRecognition', 'CharacterTrajectories', 'EigenWorms']\n",
    "ecg_datasets = ['AtrialFibrillation', 'StandWalkJump']\n",
    "eeg_meg_datasets = ['FingerMovements', 'MotorImagery', 'SelfRegulationSCP1', 'SelfRegulationSCP2', 'FaceDetection', 'HandMovementDirection']\n",
    "audio_spectra_datasets = ['DuckDuckGeese', 'Heartbeat', 'PhonemeSpectra', 'SpokenArabicDigits', 'JapaneseVowels']\n",
    "other_spatial_datasets = ['PEMS-SF', 'LSST']\n",
    "other_nonspatial_datasets = ['EthanolConcentration']\n",
    "\n",
    "spatial_datasets = human_activity_datasets + motion_datasets+other_spatial_datasets\n",
    "non_spatial_datasets = ecg_datasets + eeg_meg_datasets + audio_spectra_datasets + other_nonspatial_datasets\n",
    "print(f'There are {len(spatial_datasets)} spatial datasets and {len(non_spatial_datasets)} non-spatial datasets.')\n",
    "\n",
    "model_types = ['TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_color(color, alpha=0.5):\n",
    "    if isinstance(color, str):\n",
    "        color = mpl.colors.to_rgb(color)\n",
    "    return tuple([c + (1 - c) * (1 - alpha) for c in color])\n",
    "    \n",
    "\n",
    "def highlight_col(col, highlight_type='max', scientific_notation=False, involve_second=True):\n",
    "    if np.mean(col)>0.01:\n",
    "        col = np.round(col.values, 3)\n",
    "    else:\n",
    "        col = col.values\n",
    "    \n",
    "    if highlight_type == 'none':\n",
    "        sorted_col = np.zeros_like(col)*np.nan\n",
    "    elif highlight_type == 'max':\n",
    "        sorted_col = np.sort(col[~np.isnan(col)])[::-1]\n",
    "    elif highlight_type == 'min':\n",
    "        sorted_col = np.sort(col[~np.isnan(col)])\n",
    "    else:\n",
    "        raise ValueError(\"highlight_type must be 'none' 'max' or 'min'.\")\n",
    "    is_extreme = col==sorted_col[0]\n",
    "    is_second_extreme = col==sorted_col[1]\n",
    "    \n",
    "    styled_col = []\n",
    "    if scientific_notation and np.mean(col)<=0.01:\n",
    "        for i, v in enumerate(col):\n",
    "            if is_extreme[i]:\n",
    "                styled_col.append(f'\\\\textbf{{\\\\underline{{{v:.3E}}}}}'.replace('E-0','E-'))\n",
    "            elif is_second_extreme[i] and involve_second:\n",
    "                styled_col.append(f'\\\\textbf{{{v:.3E}}}'.replace('E-0','E-'))\n",
    "            else:\n",
    "                styled_col.append(f'{v:.3E}'.replace('E-0','E-'))\n",
    "    else:\n",
    "        for i, v in enumerate(col):\n",
    "            if is_extreme[i]:\n",
    "                styled_col.append(f'\\\\textbf{{\\\\underline{{{v:.3f}}}}}')\n",
    "            elif is_second_extreme[i] and involve_second:\n",
    "                styled_col.append(f'\\\\textbf{{{v:.3f}}}')\n",
    "            else:\n",
    "                styled_col.append(f'{v:.3f}')\n",
    "    return styled_col\n",
    "\n",
    "\n",
    "def highlight(df, max_cols=[], min_cols=[], scientific_notation=False, involve_second=True):\n",
    "    if len(max_cols)==0 and len(min_cols)==0:\n",
    "        for col in df.columns:\n",
    "            df[col] = highlight_col(df[col], 'none', scientific_notation, involve_second)\n",
    "    else:\n",
    "        for col in max_cols:\n",
    "            df[col] = highlight_col(df[col], 'max', scientific_notation, involve_second)\n",
    "        for col in min_cols:\n",
    "            df[col] = highlight_col(df[col], 'min', scientific_notation, involve_second)\n",
    "    return df\n",
    "\n",
    "def to_grayscale(fig):\n",
    "    fig.canvas.draw()\n",
    "    img = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    grayscale_img = np.dot(img[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "    fig_gray, ax_gray = plt.subplots(figsize=(fig.get_size_inches()), dpi=fig.dpi)\n",
    "    ax_gray.imshow(grayscale_img, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\n",
    "    ax_gray.axis('off')  # Turn off the axis\n",
    "    ax_gray.set_title('Grayscale plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UEA classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_uea = pd.read_csv(f'../results/evaluation/UEA_evaluation.csv', index_col=[0, 1])\n",
    "eval_uea = eval_uea.T.iloc[:-1].astype(float).T\n",
    "eval_uea = eval_uea.rename(index={'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec', \n",
    "                                  'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "\n",
    "clf_cls_loss_metrics = ['svm_acc','svm_auprc','scl_loss','sp_loss']\n",
    "dist_metrics = ['mean_shared_neighbours','mean_continuity','mean_trustworthiness','mean_dist_mrre','distmat_rmse']\n",
    "\n",
    "model_types = ['TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-specific metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial datasets\n",
    "avg_uea = eval_uea[eval_uea.index.get_level_values(1).isin(spatial_datasets)].copy()\n",
    "avg_uea = avg_uea.groupby(level=0)[clf_cls_loss_metrics].mean().loc[model_types]\n",
    "styled_uea = highlight(avg_uea, max_cols=clf_cls_loss_metrics[:2])\n",
    "styled_uea = styled_uea.style.format(decimal='.', thousands=',', precision=3)\n",
    "print(styled_uea.to_latex())\n",
    "styled_uea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-spatial datasets\n",
    "avg_uea = eval_uea[eval_uea.index.get_level_values(1).isin(non_spatial_datasets)].copy()\n",
    "avg_uea = avg_uea.groupby(level=0)[clf_cls_loss_metrics].mean().loc[model_types]\n",
    "avg_uea = np.round(avg_uea, 3)\n",
    "styled_uea = highlight(avg_uea, max_cols=clf_cls_loss_metrics[:2])\n",
    "styled_uea = styled_uea.style.format(decimal='.', thousands=',', precision=3)\n",
    "print(styled_uea.to_latex())\n",
    "styled_uea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-specific improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial datasets\n",
    "improvement = eval_uea[eval_uea.index.get_level_values(1).isin(spatial_datasets)].copy()\n",
    "metrics = ['svm_acc']\n",
    "for metric in metrics:\n",
    "    for method in model_types:\n",
    "        if 'TS2Vec' in method and method!='TS2Vec':\n",
    "            new_values = improvement.loc[method, metric].values\n",
    "            old_values = improvement.loc['TS2Vec', metric].values\n",
    "            improvement.loc[method, 'improvement_'+metric] = (new_values - old_values)/old_values*100\n",
    "        elif 'SoftCLT' in method and method!='SoftCLT':\n",
    "            new_values = improvement.loc[method, metric].values\n",
    "            old_values = improvement.loc['SoftCLT', metric].values\n",
    "            improvement.loc[method, 'improvement_'+metric] = (new_values - old_values)/old_values*100\n",
    "\n",
    "model_types = ['Topo-TS2Vec', 'GGeo-TS2Vec', 'Topo-SoftCLT', 'GGeo-SoftCLT']\n",
    "min_max_improvement = improvement.groupby(level=0)[['improvement_'+metric for metric in metrics]].agg(['min','mean','max']).loc[model_types]\n",
    "min_max_improvement = min_max_improvement.style.format(decimal='.', thousands=',', precision=3)\n",
    "\n",
    "print(min_max_improvement.to_latex())\n",
    "for model in model_types:\n",
    "    print('max', model+':', improvement.loc[model, 'improvement_svm_acc'].idxmax())\n",
    "min_max_improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-spatial datasets\n",
    "improvement = eval_uea[eval_uea.index.get_level_values(1).isin(non_spatial_datasets)].copy()\n",
    "metrics = ['svm_acc']\n",
    "for metric in metrics:\n",
    "    for method in model_types:\n",
    "        if 'TS2Vec' in method and method!='TS2Vec':\n",
    "            new_values = improvement.loc[method, metric].values\n",
    "            old_values = improvement.loc['TS2Vec', metric].values\n",
    "            improvement.loc[method, 'improvement_'+metric] = (new_values - old_values)/old_values*100\n",
    "        elif 'SoftCLT' in method and method!='SoftCLT':\n",
    "            new_values = improvement.loc[method, metric].values\n",
    "            old_values = improvement.loc['SoftCLT', metric].values\n",
    "            improvement.loc[method, 'improvement_'+metric] = (new_values - old_values)/old_values*100\n",
    "\n",
    "model_types = ['Topo-TS2Vec', 'GGeo-TS2Vec', 'Topo-SoftCLT', 'GGeo-SoftCLT']\n",
    "min_max_improvement = improvement.groupby(level=0)[['improvement_'+metric for metric in metrics]].agg(['min','mean','max']).loc[model_types]\n",
    "min_max_improvement = min_max_improvement.style.format(decimal='.', thousands=',', precision=3)\n",
    "\n",
    "print(min_max_improvement.to_latex())\n",
    "for model in model_types:\n",
    "    print('max', model+':', improvement.loc[model, 'improvement_svm_acc'].idxmax())\n",
    "min_max_improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure preservation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dist_metrics = ['local_'+metric for metric in dist_metrics]\n",
    "global_dist_metrics = ['global_'+metric for metric in dist_metrics]\n",
    "model_types = ['TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial datasets\n",
    "local_uea = eval_uea[eval_uea.index.get_level_values(1).isin(spatial_datasets)].copy()\n",
    "local_uea = local_uea.groupby(level=0)[local_dist_metrics].mean().loc[model_types]\n",
    "local_uea = highlight(local_uea, max_cols=local_dist_metrics[:3], min_cols=local_dist_metrics[3:])\n",
    "\n",
    "global_uea = eval_uea[eval_uea.index.get_level_values(1).isin(spatial_datasets)].copy()\n",
    "global_uea = global_uea.groupby(level=0)[global_dist_metrics].mean().loc[model_types]\n",
    "global_uea = highlight(global_uea, max_cols=global_dist_metrics[:3], min_cols=global_dist_metrics[3:])\n",
    "\n",
    "avg_uea = local_uea.merge(global_uea, left_index=True, right_index=True, suffixes=('_local','_global'))\n",
    "print(avg_uea.to_latex())\n",
    "avg_uea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-spatial datasets\n",
    "local_uea = eval_uea[eval_uea.index.get_level_values(1).isin(non_spatial_datasets)].copy()\n",
    "local_uea = local_uea.groupby(level=0)[local_dist_metrics].mean().loc[model_types]\n",
    "local_uea = highlight(local_uea, max_cols=local_dist_metrics[:3], min_cols=local_dist_metrics[3:])\n",
    "\n",
    "global_uea = eval_uea[eval_uea.index.get_level_values(1).isin(non_spatial_datasets)].copy()\n",
    "global_uea = global_uea.groupby(level=0)[global_dist_metrics].mean().loc[model_types]\n",
    "global_uea = highlight(global_uea, max_cols=global_dist_metrics[:3], min_cols=global_dist_metrics[3:])\n",
    "\n",
    "avg_uea = local_uea.merge(global_uea, left_index=True, right_index=True, suffixes=('_local','_global'))\n",
    "print(avg_uea.to_latex())\n",
    "avg_uea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_prediction_metrics = ['mae', 'rmse', 'error_std', 'explained_variance']\n",
    "micro_prediction_metrics = ['min_fde', 'mr_05', 'mr_1', 'mr_2']\n",
    "dist_metrics = ['mean_shared_neighbours','mean_continuity','mean_trustworthiness','mean_dist_mrre','distmat_rmse']\n",
    "model_types = ['No pretraining', 'TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_macro_continued = []\n",
    "macro_progress = pd.read_csv(f'../results/evaluation/MacroTraffic_progress_evaluation.csv', index_col=[0])\n",
    "for model in ['original','ts2vec','softclt','topo-ts2vec','ggeo-ts2vec','topo-softclt','ggeo-softclt']:\n",
    "    eval_macro_continued.append((macro_progress.loc[model].iloc[[-1]]+macro_progress.loc[model].iloc[[-2]])/2)\n",
    "eval_macro_continued = pd.concat(eval_macro_continued, axis=0)\n",
    "eval_macro_continued = eval_macro_continued.T.iloc[1:].astype(float).T\n",
    "eval_macro_continued = eval_macro_continued.rename(index={'original':'No pretraining', 'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec',\n",
    "                                                          'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "eval_macro_continued = eval_macro_continued.loc[model_types]\n",
    "\n",
    "eval_micro_continued = pd.read_csv(f'../results/evaluation/MicroTraffic_continued_evaluation.csv', index_col=[0])\n",
    "eval_micro_continued = eval_micro_continued.T.iloc[1:].astype(float).T\n",
    "eval_micro_continued = eval_micro_continued.rename(index={'original':'No pretraining', 'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec',\n",
    "                                                          'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "eval_micro_continued = eval_micro_continued.loc[model_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-specific metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_traffic = eval_macro_continued[macro_prediction_metrics].merge(eval_micro_continued[micro_prediction_metrics], left_index=True, right_index=True)\n",
    "styled_traffic['explained_variance'] = styled_traffic['explained_variance']*100\n",
    "\n",
    "old_best = styled_traffic.loc['No pretraining']\n",
    "new_best = styled_traffic.min(axis=0)\n",
    "new_best['explained_variance'] = styled_traffic['explained_variance'].max()\n",
    "\n",
    "styled_traffic = highlight(styled_traffic, \n",
    "                           max_cols=macro_prediction_metrics[3:],\n",
    "                           min_cols=macro_prediction_metrics[:3]+micro_prediction_metrics)\n",
    "styled_traffic.loc['Best improvement'] = np.round(abs(new_best - old_best)/(old_best)*100, 3)\n",
    "styled_traffic = styled_traffic.style.format(decimal='.', thousands=',', precision=3)\n",
    "print(styled_traffic.to_latex())\n",
    "styled_traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local structure preservation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_traffic = eval_macro_continued[['local_'+metric for metric in dist_metrics]].merge(\n",
    "    eval_micro_continued[['local_'+metric for metric in dist_metrics]],\n",
    "    left_index=True, right_index=True, suffixes=('_macro', '_micro'))\n",
    "styled_traffic = highlight(styled_traffic,\n",
    "                       min_cols=['local_'+metric+'_micro' for metric in dist_metrics[3:]]+['local_'+metric+'_macro' for metric in dist_metrics[3:]],\n",
    "                       max_cols=['local_'+metric+'_macro' for metric in dist_metrics[:3]]+['local_'+metric+'_micro' for metric in dist_metrics[:3]])\n",
    "print(styled_traffic.to_latex())\n",
    "styled_traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global structure preservation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_traffic = eval_macro_continued[['global_'+metric for metric in dist_metrics]].merge(\n",
    "    eval_micro_continued[['global_'+metric for metric in dist_metrics]],\n",
    "    left_index=True, right_index=True, suffixes=('_macro', '_micro'))\n",
    "styled_traffic = highlight(styled_traffic,\n",
    "                       min_cols=['global_'+metric+'_micro' for metric in dist_metrics[3:]]+['global_'+metric+'_macro' for metric in dist_metrics[3:]],\n",
    "                       max_cols=['global_'+metric+'_macro' for metric in dist_metrics[:3]]+['global_'+metric+'_micro' for metric in dist_metrics[:3]])\n",
    "print(styled_traffic.to_latex())\n",
    "styled_traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ['TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSRL training time per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_training_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_uea = pd.read_csv(f'../results/evaluation/UEA_training_efficiency.csv', index_col=[0, 1])\n",
    "eval_uea = eval_uea.T.iloc[:-1].astype(float).T.reset_index().rename(columns={'level_0':'model', 'level_1':'dataset'})\n",
    "eval_uea['training_time_per_epoch'] = eval_uea['training_time']/eval_uea['training_epochs']\n",
    "baseline_training_time = 0.\n",
    "num_datasets = eval_uea['dataset'].nunique()\n",
    "for dataset in eval_uea['dataset'].unique():\n",
    "    baseline = eval_uea[(eval_uea['model']=='ts2vec')&(eval_uea['dataset']==dataset)]['training_time_per_epoch'].values[0]\n",
    "    baseline_training_time += baseline\n",
    "    for model in eval_uea['model'].unique():\n",
    "        eval_uea.loc[(eval_uea['model']==model)&(eval_uea['dataset']==dataset), 'unit_training_time'] = eval_uea[(eval_uea['model']==model)&(eval_uea['dataset']==dataset)]['training_time_per_epoch'].values[0]/baseline\n",
    "eval_uea = eval_uea.groupby('model')[['unit_training_time']].mean()\n",
    "eval_uea = eval_uea.rename(index={'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec',\n",
    "                                  'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "eval_uea = eval_uea.T\n",
    "eval_uea['base_training_time'] = baseline_training_time/num_datasets\n",
    "eval_uea = eval_uea.rename(index={'unit_training_time':'CNN'})[['base_training_time']+model_types]\n",
    "\n",
    "repr_training_time.append(eval_uea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_micro = pd.read_csv(f'../results/evaluation/MicroTraffic_training_efficiency.csv', index_col=[0])\n",
    "eval_macro = pd.read_csv(f'../results/evaluation/MacroTraffic_training_efficiency.csv', index_col=[0])\n",
    "eval_lstm = pd.read_csv(f'../results/evaluation/MacroLSTM_training_efficiency.csv', index_col=[0])\n",
    "eval_gru = pd.read_csv(f'../results/evaluation/MacroGRU_training_efficiency.csv', index_col=[0])\n",
    "\n",
    "for eval_, encoder in zip([eval_micro, eval_macro, eval_lstm, eval_gru], ['VectorNet','DGCN','LSTM','GRU']):\n",
    "    eval_.rename(index={'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec', \n",
    "                        'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'}, inplace=True)\n",
    "    eval_['training_time_per_epoch'] = eval_['training_time']/eval_['training_epochs']\n",
    "    eval_ = eval_[['training_time_per_epoch']].copy().T.rename(index={'training_time_per_epoch':encoder})\n",
    "    eval_['base_training_time'] = eval_['TS2Vec']\n",
    "    for model in model_types:\n",
    "        eval_.loc[encoder, model] = eval_[model].values[0]/eval_['base_training_time'].values[0]\n",
    "    repr_training_time.append(eval_)\n",
    "\n",
    "repr_training_time = pd.concat(repr_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_training_time['base_training_time'] = [f'{v:.2f}' for v in repr_training_time['base_training_time'].values]\n",
    "for model_type in model_types:\n",
    "    values = repr_training_time[model_type].values\n",
    "    repr_training_time[model_type] = [f'{v:.2f}$\\\\times$' for v in values.astype(float)]\n",
    "print(repr_training_time.to_latex())\n",
    "repr_training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning progress curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_metrics = ['mean_shared_neighbours','mean_continuity','mean_trustworthiness','mean_dist_mrre','distmat_rmse']\n",
    "global_dist_metrics = ['global_'+metric for metric in dist_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,3,figsize=(7.5,5.5), sharex='col', constrained_layout=True, \n",
    "                         gridspec_kw={'hspace':0., 'wspace':0., 'height_ratios':[1.6,1,1,1,1,1]})\n",
    "\n",
    "models = ['original','ts2vec','topo-ts2vec','ggeo-ts2vec','softclt','topo-softclt','ggeo-softclt']\n",
    "model_types = ['No pretraining', 'TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']\n",
    "# colors = plt.cm.Set1(np.linspace(0, 0.77, 7))[[0,4,6,3,5,1,2]]\n",
    "colors = plt.cm.tab20([0.325, 0.025, 0.125, 0.225, 0.425, 0.825, 0.925])\n",
    "markers = ['o', 's', '^', '<', 'D', 'v', '>']\n",
    "\n",
    "for col, encoder in enumerate(['DGCN','LSTM','GRU']):\n",
    "    if encoder == 'DGCN':\n",
    "        eval_ = pd.read_csv(f'../results/evaluation/MacroTraffic_progress_evaluation.csv', index_col=[0])\n",
    "    else:\n",
    "        eval_ = pd.read_csv(f'../results/evaluation/Macro{encoder}_progress_evaluation.csv', index_col=[0])\n",
    "\n",
    "    ylim_list = {'DGCN': [5.83, 6.34], 'LSTM': [5.9, 7.2], 'GRU': [6.4, 8.2]}\n",
    "    for model, color, model_type, marker in zip(models, colors, model_types, markers):\n",
    "        selected_var = 'rmse'\n",
    "\n",
    "        if model == 'original':\n",
    "            ax_focus = axes[0,col].inset_axes([0.4, 0.38, 0.58, 0.6], \n",
    "                                              xlim=(6*14.5, 6*30.5), \n",
    "                                              ylim=(ylim_list[encoder][0], ylim_list[encoder][1]))\n",
    "            ax_focus.tick_params(axis='both', labelsize=8, pad=1)\n",
    "            # ax_focus.set_yticks([85, 90, 95, 100])\n",
    "            ax_focus.set_xticks([90, 120, 150, 180])\n",
    "            rect, lines = axes[0,col].indicate_inset_zoom(ax_focus, edgecolor='k')\n",
    "            for line in lines:\n",
    "                line.set_color('k')\n",
    "                line.set_linestyle('--')\n",
    "                line.set_linewidth(0.5)\n",
    "            rect.set_edgecolor('k')\n",
    "            rect.set_linestyle('--')\n",
    "            rect.set_linewidth(0.5)\n",
    "        ax_focus.plot(6*(eval_.loc[model]['epoch']+1), eval_.loc[model][selected_var], label=model_type, alpha=0.8,\n",
    "                        lw=0.7, color=color, marker=marker, markersize=2.5, markerfacecolor='none', markeredgewidth=0.7)\n",
    "        for row, var in zip([0, 1, 2, 3, 4, 5], [selected_var]+global_dist_metrics):\n",
    "            if row==0:\n",
    "                axes[row, col].plot(6*(eval_.loc[model]['epoch']+1), eval_.loc[model][var], label=model_type, alpha=0.8, color=color,\n",
    "                                    lw=0.7, marker=marker, markersize=2.5, markerfacecolor='none', markeredgewidth=0.7)\n",
    "            else:\n",
    "                axes[row, col].plot(6*(eval_.loc[model]['epoch']+1), eval_.loc[model][var], color=color,\n",
    "                                    lw=1, alpha=0.8)\n",
    "                axes[row, col].plot(6*(eval_.loc[model]['epoch']+1), eval_.loc[model][var], color=color,\n",
    "                                    lw=0., marker=marker, markersize=2.5, markerfacecolor='none', markeredgewidth=0.3)\n",
    "    \n",
    "    axes[0, col].set_title(encoder, fontsize=9, pad=4)\n",
    "    axes[0, col].set_ylim(5.5, 14.9)\n",
    "    axes[-1, col].set_xlabel('Epochs', labelpad=0)\n",
    "    axes[-1, col].set_xlim(-3, 183)\n",
    "    axes[-1, col].set_xticks([0, 60, 120, 180])\n",
    "\n",
    "for row, ylabel in zip(range(6), ['RMSE', 'kNN', 'Cont.', 'Trust.', 'MRRE', 'dRMSE']):\n",
    "    axes[row, 0].set_ylabel(ylabel)\n",
    "\n",
    "handles, labels = axes[0, 1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels,\n",
    "           loc='lower center', ncol=7, fontsize=9,\n",
    "           frameon=False, bbox_to_anchor=(0.51, -0.05),\n",
    "           handletextpad=0.3, columnspacing=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('macro_traffic_progress.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_uea = pd.read_csv(f'../results/evaluation/UEA_evaluation.csv', index_col=[0, 1])\n",
    "eval_uea = eval_uea.rename(index={'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec', \n",
    "                                  'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "eval_uea['svm_acc'] = np.round(eval_uea['svm_acc'], 3)\n",
    "dim_uea = pd.read_csv(f'../datasets/UEA_DataDimensions.csv', index_col=0).set_index('Problem')\n",
    "\n",
    "ts2vec_wins = dict()\n",
    "softclt_wins = dict()\n",
    "ties = dict()\n",
    "for dataset in eval_uea.index.get_level_values(1).unique():\n",
    "    eval_dataset = eval_uea.loc[(slice(None), dataset), :].reset_index(level=1, drop=True)\n",
    "    ts2vec_best = eval_dataset.loc[['TS2Vec','Topo-TS2Vec','GGeo-TS2Vec']]['svm_acc'].idxmax()\n",
    "    softclt_best = eval_dataset.loc[['SoftCLT','Topo-SoftCLT','GGeo-SoftCLT']]['svm_acc'].idxmax()\n",
    "    if eval_dataset.loc[ts2vec_best, 'svm_acc']>eval_dataset.loc[softclt_best, 'svm_acc']:\n",
    "        ts2vec_wins[dataset] = dim_uea.loc[dataset, 'NumClasses']\n",
    "    elif eval_dataset.loc[ts2vec_best, 'svm_acc']<eval_dataset.loc[softclt_best, 'svm_acc']:\n",
    "        softclt_wins[dataset] = dim_uea.loc[dataset, 'NumClasses']\n",
    "    else:\n",
    "        ties[dataset] = dim_uea.loc[dataset, 'NumClasses']\n",
    "\n",
    "ts2vec_wins = pd.Series(ts2vec_wins).sort_values()\n",
    "softclt_wins = pd.Series(softclt_wins).sort_values()\n",
    "ties = pd.Series(ties).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.5,2), constrained_layout=True)\n",
    "_ = ax.boxplot([softclt_wins], positions=[1],\n",
    "           vert=False, widths=0.5, patch_artist=True, showfliers=True, showmeans=False, meanline=False,\n",
    "           boxprops=dict(facecolor='tab:blue', color='tab:blue', linewidth=1, alpha=0.4),\n",
    "           whiskerprops=dict(color='tab:blue', linewidth=0.5),\n",
    "           capprops=dict(color='tab:blue', linewidth=0.5),\n",
    "           medianprops=dict(color='tab:blue', linewidth=1),\n",
    "           )\n",
    "_ = ax.boxplot([ts2vec_wins], positions=[3],\n",
    "              vert=False, widths=0.5, patch_artist=True, showfliers=True, showmeans=False, meanline=False,\n",
    "              boxprops=dict(facecolor='tab:orange', color='tab:orange', linewidth=1, alpha=0.4),\n",
    "              whiskerprops=dict(color='tab:orange', linewidth=0.5),\n",
    "              capprops=dict(color='tab:orange', linewidth=0.5),\n",
    "              medianprops=dict(color='tab:orange', linewidth=1),\n",
    "              )\n",
    "_ = ax.scatter(ties, [2]*len(ties), color='tab:green', marker='o', s=15, alpha=0.8, facecolors='none', linewidths=0.8)\n",
    "\n",
    "ax.set_yticks([1,2,3])\n",
    "ax.set_yticklabels(['(Topo/GGeo-)SoftCLT\\n best performed', \n",
    "                    '(Topo/GGeo-)TS2Vec and\\n (Topo/GGeo-)SoftCLT\\n both best performed',\n",
    "                    '(Topo/GGeo-)TS2Vec\\n best performed'])\n",
    "ax.set_xlabel('Number of classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('uea_num_classes.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed results of UEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ['TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification accuracy spatial datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_uea = pd.read_csv(f'../results/evaluation/UEA_evaluation.csv', index_col=[0, 1])\n",
    "eval_uea = eval_uea.rename(index={'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec', \n",
    "                                  'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "\n",
    "detailed_uea = eval_uea[eval_uea.index.get_level_values(1).isin(spatial_datasets)].copy()\n",
    "detailed_uea = detailed_uea.reset_index().pivot(index='dataset', columns='model', values='svm_acc')\n",
    "detailed_uea = detailed_uea.T.loc[model_types].T.sort_index()\n",
    "detailed_uea.loc['Avg. over spatial datasets'] = detailed_uea.mean(axis=0)\n",
    "detailed_uea = highlight(detailed_uea.T, \n",
    "                         max_cols=detailed_uea.T.columns,\n",
    "                         involve_second=False).T \n",
    "print(detailed_uea.to_latex())\n",
    "detailed_uea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification accuracy non-spatial datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_uea = eval_uea[eval_uea.index.get_level_values(1).isin(non_spatial_datasets)].copy()\n",
    "detailed_uea = detailed_uea.reset_index().pivot(index='dataset', columns='model', values='svm_acc')\n",
    "detailed_uea = detailed_uea.T.loc[model_types].T.sort_index()\n",
    "detailed_uea.loc['Avg. over non-spatial datasets'] = detailed_uea.mean(axis=0)\n",
    "detailed_uea = highlight(detailed_uea.T, \n",
    "                         max_cols=detailed_uea.T.columns,\n",
    "                         involve_second=False).T \n",
    "print(detailed_uea.to_latex())\n",
    "detailed_uea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time spatial datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_uea = pd.read_csv(f'../results/evaluation/UEA_training_efficiency.csv', index_col=[0, 1])\n",
    "eval_uea = eval_uea.rename(index={'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec', \n",
    "                                  'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "\n",
    "detailed_uea = eval_uea[eval_uea.index.get_level_values(1).isin(spatial_datasets)].copy()\n",
    "detailed_uea['train_time_per_epoch'] = detailed_uea['training_time']/detailed_uea['training_epochs']\n",
    "detailed_uea = detailed_uea.reset_index().pivot(index='dataset', columns='model', values='train_time_per_epoch')\n",
    "detailed_uea = detailed_uea.T.loc[model_types].T.sort_index()\n",
    "detailed_uea.loc['Avg. over spatial datasets'] = detailed_uea.mean(axis=0)\n",
    "detailed_uea = highlight(detailed_uea.T).T\n",
    "\n",
    "avg_multipliers = []\n",
    "for model in model_types:\n",
    "    if model=='TS2Vec':\n",
    "        baselines = detailed_uea[model].values\n",
    "        detailed_uea[model] = detailed_uea[model].astype(str) + ' (1.00$\\\\times$)'\n",
    "    else:\n",
    "        values = detailed_uea[model].values\n",
    "        detailed_uea[model] = [f'{v} ({v/b:.2f}$\\\\times$)' for v, b in zip(values.astype(float), baselines.astype(float))]\n",
    "        avg_multipliers.append(np.mean(values.astype(float)/baselines.astype(float)))\n",
    "avg_baseline = baselines.astype(float).mean()\n",
    "\n",
    "detailed_uea.loc['Avg. over spatial datasets', 'TS2Vec'] = avg_baseline\n",
    "detailed_uea.loc['Avg. over spatial datasets', model_types[1:]] = [f'{v:.2f}$\\\\times$' for v in avg_multipliers]\n",
    "\n",
    "print(detailed_uea.to_latex())\n",
    "detailed_uea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time non-spatial datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_uea = eval_uea[eval_uea.index.get_level_values(1).isin(non_spatial_datasets)].copy()\n",
    "detailed_uea['train_time_per_epoch'] = detailed_uea['training_time']/detailed_uea['training_epochs']\n",
    "detailed_uea = detailed_uea.reset_index().pivot(index='dataset', columns='model', values='train_time_per_epoch')\n",
    "detailed_uea = detailed_uea.T.loc[model_types].T.sort_index()\n",
    "detailed_uea.loc['Avg. over non-spatial datasets'] = detailed_uea.mean(axis=0)\n",
    "detailed_uea = highlight(detailed_uea.T).T\n",
    "\n",
    "avg_multipliers = []\n",
    "for model in model_types:\n",
    "    if model=='TS2Vec':\n",
    "        baselines = detailed_uea[model].values\n",
    "        detailed_uea[model] = detailed_uea[model].astype(str) + ' (1.00$\\\\times$)'\n",
    "    else:\n",
    "        values = detailed_uea[model].values\n",
    "        detailed_uea[model] = [f'{v} ({v/b:.2f}$\\\\times$)' for v, b in zip(values.astype(float), baselines.astype(float))]\n",
    "        avg_multipliers.append(np.mean(values.astype(float)/baselines.astype(float)))\n",
    "avg_baseline = baselines.astype(float).mean()\n",
    "\n",
    "detailed_uea.loc['Avg. over non-spatial datasets', 'TS2Vec'] = avg_baseline\n",
    "detailed_uea.loc['Avg. over non-spatial datasets', model_types[1:]] = [f'{v:.2f}$\\\\times$' for v in avg_multipliers]\n",
    "\n",
    "print(detailed_uea.to_latex())\n",
    "detailed_uea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM and GRU evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_prediction_metrics = ['mae', 'rmse', 'error_std', 'explained_variance']\n",
    "dist_metrics = ['mean_shared_neighbours','mean_continuity','mean_trustworthiness','mean_dist_mrre','distmat_rmse']\n",
    "model_types = ['No pretraining', 'TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task-specific metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lstm_continued = []\n",
    "lstm_progress = pd.read_csv(f'../results/evaluation/MacroLSTM_progress_evaluation.csv', index_col=[0])\n",
    "for model in ['original','ts2vec','softclt','topo-ts2vec','ggeo-ts2vec','topo-softclt','ggeo-softclt']:\n",
    "    eval_lstm_continued.append((lstm_progress.loc[model].iloc[[-1]]+lstm_progress.loc[model].iloc[[-2]])/2)\n",
    "eval_lstm_continued = pd.concat(eval_lstm_continued, axis=0)\n",
    "eval_lstm_continued = eval_lstm_continued.T.iloc[1:].astype(float).T\n",
    "eval_lstm_continued = eval_lstm_continued.rename(index={'original':'No pretraining', 'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec',\n",
    "                                                        'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "eval_lstm_continued = eval_lstm_continued.loc[model_types]\n",
    "\n",
    "eval_gru_continued = []\n",
    "gru_progress = pd.read_csv(f'../results/evaluation/MacroGRU_progress_evaluation.csv', index_col=[0])\n",
    "for model in ['original','ts2vec','softclt','topo-ts2vec','ggeo-ts2vec','topo-softclt','ggeo-softclt']:\n",
    "    eval_gru_continued.append((gru_progress.loc[model].iloc[[-1]]+gru_progress.loc[model].iloc[[-2]])/2)\n",
    "eval_gru_continued = pd.concat(eval_gru_continued, axis=0)\n",
    "eval_gru_continued = eval_gru_continued.T.iloc[1:].astype(float).T\n",
    "eval_gru_continued = eval_gru_continued.rename(index={'original':'No pretraining', 'ts2vec':'TS2Vec', 'topo-ts2vec':'Topo-TS2Vec', 'ggeo-ts2vec':'GGeo-TS2Vec',\n",
    "                                                      'softclt':'SoftCLT', 'topo-softclt':'Topo-SoftCLT', 'ggeo-softclt':'GGeo-SoftCLT'})\n",
    "eval_gru_continued = eval_gru_continued.loc[model_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_traffic = eval_lstm_continued[macro_prediction_metrics].merge(\n",
    "    eval_gru_continued[macro_prediction_metrics],\n",
    "    left_index=True, right_index=True,\n",
    "    suffixes=('_lstm', '_gru'))\n",
    "styled_traffic['explained_variance_lstm'] = styled_traffic['explained_variance_lstm']*100\n",
    "styled_traffic['explained_variance_gru'] = styled_traffic['explained_variance_gru']*100\n",
    "\n",
    "old_best = styled_traffic.loc['No pretraining']\n",
    "new_best = styled_traffic.min(axis=0)\n",
    "new_best['explained_variance_lstm'] = styled_traffic['explained_variance_lstm'].max()\n",
    "new_best['explained_variance_gru'] = styled_traffic['explained_variance_gru'].max()\n",
    "\n",
    "styled_traffic = highlight(styled_traffic, \n",
    "                           max_cols=['explained_variance_lstm', 'explained_variance_gru'],\n",
    "                           min_cols=['mae_lstm', 'rmse_lstm', 'error_std_lstm', 'mae_gru', 'rmse_gru', 'error_std_gru'])\n",
    "styled_traffic.loc['Best improvement'] = np.round(abs(new_best - old_best)/(old_best)*100, 3)\n",
    "styled_traffic = styled_traffic.style.format(decimal='.', thousands=',', precision=3)\n",
    "print(styled_traffic.to_latex())\n",
    "styled_traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global structure preservation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_traffic = eval_lstm_continued[['global_'+metric for metric in dist_metrics]].merge(\n",
    "    eval_gru_continued[['global_'+metric for metric in dist_metrics]],\n",
    "    left_index=True, right_index=True, suffixes=('_lstm', '_gru'))\n",
    "styled_traffic = highlight(styled_traffic,\n",
    "                       min_cols=['global_'+metric+'_lstm' for metric in dist_metrics[3:]]+['global_'+metric+'_gru' for metric in dist_metrics[3:]],\n",
    "                       max_cols=['global_'+metric+'_lstm' for metric in dist_metrics[:3]]+['global_'+metric+'_gru' for metric in dist_metrics[:3]])\n",
    "print(styled_traffic.to_latex())\n",
    "styled_traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epilepsy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = 'UEA'\n",
    "dataset = 'Epilepsy'\n",
    "model_names = ['ts2vec', 'topo-ts2vec', 'ggeo-ts2vec', 'softclt', 'topo-softclt', 'ggeo-softclt']\n",
    "model_types = ['TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']\n",
    "\n",
    "fig = plt.figure(figsize=(13., 3.))\n",
    "for ax_id, model_name in tqdm(enumerate(model_names), total=len(model_types)):\n",
    "    latents = np.load(f'../results/pretrain/{loader}/{model_name}/{dataset}/latents_global.npz')\n",
    "    labels = latents['labels']\n",
    "    latents = latents['latents']\n",
    "\n",
    "    reducer = TSNE(n_components=3, random_state=131, perplexity=15, learning_rate='auto')\n",
    "    latents_3d = reducer.fit_transform(latents)\n",
    "    latents_3d = (latents_3d - np.min(latents_3d, axis=0)) / (np.max(latents_3d, axis=0) - np.min(latents_3d, axis=0))\n",
    "\n",
    "    ax = fig.add_subplot(1, len(model_types), ax_id+1, projection='3d')\n",
    "    ax.scatter(latents_3d[:, 0], latents_3d[:, 1], latents_3d[:, 2], c=labels, cmap='tab20')\n",
    "\n",
    "    ax.set_title(model_types[ax_id])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('Epilepsy_latents.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RacketSports dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = 'UEA'\n",
    "dataset = 'RacketSports'\n",
    "model_names = ['ts2vec', 'topo-ts2vec', 'ggeo-ts2vec', 'softclt', 'topo-softclt', 'ggeo-softclt']\n",
    "model_types = ['TS2Vec', 'Topo-TS2Vec', 'GGeo-TS2Vec', 'SoftCLT', 'Topo-SoftCLT', 'GGeo-SoftCLT']\n",
    "\n",
    "fig = plt.figure(figsize=(13., 3.))\n",
    "for ax_id, model_name in tqdm(enumerate(model_names), total=len(model_types)):\n",
    "    latents = np.load(f'../results/pretrain/{loader}/{model_name}/{dataset}/latents_global.npz')\n",
    "    labels = latents['labels']\n",
    "    latents = latents['latents']\n",
    "\n",
    "    reducer = TSNE(n_components=3, random_state=131, perplexity=17, learning_rate='auto')\n",
    "    latents_3d = reducer.fit_transform(latents)\n",
    "    latents_3d = (latents_3d - np.min(latents_3d, axis=0)) / (np.max(latents_3d, axis=0) - np.min(latents_3d, axis=0))\n",
    "\n",
    "    ax = fig.add_subplot(1, len(model_types), ax_id+1, projection='3d')\n",
    "    ax.scatter(latents_3d[:, 0], latents_3d[:, 1], latents_3d[:, 2], c=labels, cmap='tab20')\n",
    "\n",
    "    ax.set_title(model_types[ax_id])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('RacketSports_latents.pdf', bbox_inches='tight', dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trafficscl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
